import json
from dotenv import load_dotenv
from openai import OpenAI
from ai_research.services.get_weather import get_weather

load_dotenv()

client = OpenAI()

tools = [
    {
        "type": "function",
        "name": "get_weather",
        "description": "Get current temperature for a given location.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "City and country e.g. Bogotá, Colombia",
                }
            },
            "required": ["location"],
            "additionalProperties": False,
        },
        "strict": True,
    },
]

# 1) Mensagem inicial do usuário
input_list = [
    {"role": "user", "content": "What is the weather like in Paris today?"}
]

# 2) Primeira chamada com tools
response = client.responses.create(
    model="gpt-5",
    tools=tools,
    input=input_list,
)

# Acrescenta as saídas no histórico
input_list += response.output

# 3) Se houver function_call para get_weather, executa localmente e devolve o output
for item in response.output:
    if item.type == "function_call" and item.name == "get_weather":
        args = json.loads(item.arguments)  # arguments é string JSON
        location = args["location"]

        # Chama sua função (que já busca no OpenWeatherMap)
        weather_str = get_weather(location)

        # Anexa o retorno da função ao histórico
        input_list.append({
            "type": "function_call_output",
            "call_id": item.call_id,
            "output": json.dumps({"weather": weather_str}),
        })

# 4) Segunda chamada: peça só a resposta final ao usuário
final = client.responses.create(
    model="gpt-5",
    instructions="Respond only with the weather string generated by a tool.",
    tools=tools,
    input=input_list,
)

print(final.output_text)  # <- resposta final para o usuário